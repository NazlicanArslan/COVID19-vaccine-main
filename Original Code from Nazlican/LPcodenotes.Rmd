---
title: "LP Research Diary"
output: pdf_document
fontsize: 12pt

header-includes:
- \usepackage{setspace}\doublespacing
---

# 08102022 Meeting

## Notes on Original Code

- Important inconsistency:
  - The ```delta_update``` and ```omicron_update``` methods in the ```Vaccine_group``` class (in ```vaccine_params.py```) update ```v_beta_reduct``` and ```v_tau_reduct``` for each vaccine group \textit{in place}. Vaccine groups do not get reset within a replication. The value of ```v_beta_reduct``` at time $t+1$ is computed based on its value in the previous time period $t$. 
  - The ```delta_update_param``` and ```omicron_update_param``` methods in the ```EpiSetup``` class (in ```epi_params.py```) update lots of parameters, also \textit{in place}. However, between each timepoint within a replication, the ```EpiSetup``` instance essentially gets reset. See ```epi = copy.deepcopy(epi_rand)``` call within the ```simulate_t``` function. The value of each updated parameter at time $t+1$ is computed based on its \textit{original value} at time $0$.
  - If this copying (resetting) of the ```EpiSetup``` instance does not happen, then the code does not work -- some of the updated parameters become negative (and the mathematics of the update are also different). 
  - I'm documenting this because it's important to note.
  
- Inconsistency on data types
  - In each ```Vaccine_group``` instance, the simulation variables for that vaccine group are instantiated as floats, but then reset as integers. Not super sure what the difference between the conditions of ```types = "int"``` and ```types = "float"``` in the simulation computation, but there is a small difference in the rsquared output. I think it's better to just make the sensitive data types doubles.

# 08052022 Documentation of Important Bug

## Overview of Problem

- Suppose that we run a simulation with seeds 1,2,3. The $R^2$ for any seed is different if it is simulated first rather than simulated after another seed. Conditional on a seed not being simulated first, the seed's $R^2$ is the same, regardless of order. 
- Similarly, if we run a simulation with seed 1, and then run the simulation again with seed 1, the $R^2$'s are different.
- At first, I thought that this only meant the first replication (or first seed being tested) was incorrect, and perhaps there was some initialization that was happening in the first replication.
- Unfortunately, this is not the case. The inverse is true. \textit{Only the first replication is correct.} All subsequent replications after the first replication are incorrect.
- The reason is that the vaccine history is not being properly reset in between replications! 
- Between replications, a $\texttt{Vaccine}$ instance is passed. This instance contains attributes such as \texttt{v\_beta\_reduct} and \texttt{v\_tau\_reduct}, which are supposed to decrease over time, corresponding to decreased efficacy against the Delta variant and Omicron variant, respectively. Only \textit{some} of the vaccine history is cleared between replications. The aforementioned efficacy attributes are \textit{not} cleared. Therefore, they carry over to subsequent replications. That is why every replication after the first replication is incorrect.
- Below, I'll explain why conditional on a seed not being simulated first, the seed's $R^2$ is the same, regardless of order.

## Code Details

- These details are about the original code (without my edits).
- In between replications, the function ```stoch_simulation_iterator``` in ```threshold_policy.py``` calls ```vaccine_policy.reset_vaccine_history()``` which is intended to clear the vaccine history. Here, ```vaccine_policy``` is an instance of the ```VaccineAllocationPolicy``` class in ```vaccine_policies.py```. ```vaccine_policy.reset_vaccine_history()``` calls ```v_group.reset_history()``` for every vaccine group. Each ```v_group``` is an instance of the ```VaccineGroup``` class in ```vaccine_params.py```. 
- Below I have pasted the code for the method ```reset_history()``` -- the important SEIR states are reset to $0$, but crucially, some attributes are not reset. 

```{}
    def reset_history(self, instance, seed):
        '''
            reset history for a new simulation.
        '''
        T, A, L = instance.T, instance.A, instance.L
        step_size = config['step_size']
       
        types = 'int' if seed >= 0 else 'float'
        # breakpoint()
        
        self.S = np.zeros((T, A, L), dtype=types)
        self.E = np.zeros((T, A, L), dtype=types)
        self.IA = np.zeros((T, A, L), dtype=types)
        self.IY = np.zeros((T, A, L), dtype=types)
        self.PA = np.zeros((T, A, L), dtype=types)
        self.PY = np.zeros((T, A, L), dtype=types)
        self.IH = np.zeros((T, A, L), dtype=types)
        self.ICU = np.zeros((T, A, L), dtype=types)
        self.R = np.zeros((T, A, L), dtype=types)
        self.D = np.zeros((T, A, L), dtype=types)
        self.IYIH = np.zeros((T - 1, A, L))
        self.IYICU = np.zeros((T - 1, A, L))
        self.IHICU = np.zeros((T - 1, A, L))
        self.ToICU = np.zeros((T - 1, A, L))
        self.ToIHT = np.zeros((T - 1, A, L))
        self.ToICUD = np.zeros((T - 1, A, L))
        self.ToIYD = np.zeros((T - 1, A, L))
        self.ToIA = np.zeros((T - 1, A, L))   
        self.ToIY = np.zeros((T - 1, A, L))
        
        self._S = np.zeros((step_size + 1, A, L), dtype=types)
        self._E = np.zeros((step_size + 1, A, L), dtype=types)
        self._IA = np.zeros((step_size + 1, A, L), dtype=types)
        self._IY = np.zeros((step_size + 1, A, L), dtype=types)
        self._PA = np.zeros((step_size + 1, A, L), dtype=types)
        self._PY = np.zeros((step_size + 1, A, L), dtype=types)
        self._IH = np.zeros((step_size + 1, A, L), dtype=types)
        self._ICU = np.zeros((step_size + 1, A, L), dtype=types)
        self._R = np.zeros((step_size + 1, A, L), dtype=types)
        self._D = np.zeros((step_size + 1, A, L), dtype=types)
        self._IYIH = np.zeros((step_size, A, L))
        self._IYICU = np.zeros((step_size, A, L))
        self._IHICU = np.zeros((step_size, A, L))
        self._ToICU = np.zeros((step_size, A, L))
        self._ToIHT = np.zeros((step_size, A, L))
        self._ToICUD = np.zeros((step_size, A, L))
        self._ToIYD = np.zeros((step_size, A, L))          
        self._ToIA = np.zeros((T - 1, A, L))   
        self._ToIY = np.zeros((T - 1, A, L))
        
        if self.v_name == 'v_0':
            N, I0 = instance.N, instance.I0
            # Initial Conditions (assumed)
            self.PY[0] = I0
            self.R[0] = 0
            self.S[0] = N - self.PY[0] - self.IY[0]
                
        self._S[0] = self.S[0].copy()
        self._E[0] = self.E[0].copy()
        self._IA[0] = self.IA[0].copy()
        self._IY[0] = self.IY[0].copy()
        self._PA[0] = self.PA[0].copy()
        self._PY[0] = self.PY[0].copy()
        self._IH[0] = self.IH[0].copy()
        self._ICU[0] = self.ICU[0].copy()
        self._R[0] = self.R[0].copy()
        self._D[0] = self.D[0].copy()
```

- Below I have pasted the code for two methods of ```VaccineGroup``` objects that modify two attributes ```v_beta_reduct``` and ```v_tau_reduct.```
- The very initial values of ```v_beta_reduct``` and ```v_tau_reduct``` (their values at the beginning of the very first simulation replication) are read in from user-specified data. I will omit the details, but see ```__init__`` and ```define_groups``` in the ```Vaccine``` class and ```__init__``` in the ```VaccineGroup``` class (both classes are in ```vaccine_params.py```).

```{}
    def delta_update(self, prev):
        '''
            Update efficacy according to delta variant (VoC) prevelance.
        '''
        
        self.v_beta_reduct = self.v_beta_reduct * (1 - prev) + 
          self.v_beta_reduct_delta * prev #decreased efficacy against infection.
        self.v_tau_reduct = self.v_tau_reduct * (1 - prev) + 
          self.v_tau_reduct_delta * prev #decreased efficacy against symptomatic infection.    
     
    def omicron_update(self, prev):
        '''
            Update efficacy according to omicron variant (VoC) prevelance.
        '''
        self.v_tau_reduct = self.v_tau_reduct * (1 - prev) + 
          self.v_tau_reduct_omicron * prev
```

- To test my hypothesis thoroughly, I ran 2 replications of the same seed back-to-back (seed 100). 
- I modified the ```delta_update``` method to print "Delta Update" and the ```v_beta_reduct``` attribute as well as the ```prev``` argument for vaccine group ```"v_2"``` before the ```v_beta_reduct``` attribute is updated. (Note that analogous behavior occurs for all groups.)
- The output is saved in ```08052022DeltaUpdateRep1.txt``` and ```08052022DeltaUpdateRep2.txt.``` 
- These files are very long, but the beginning and end of the files are what we are interested in.
- Although not documented in another text file, the $R^2$ for replication 2 and replication 3 (for the same seed, seed 100), is indeed the same. 

- For replication 1, the initial ```v_beta_reduct``` is $0.9$ and the ```prev``` argument passed to it is $0.01$.
  - The last values are $.7$ and $1.0$ respectively, and the second-to-last values are also $.7$ and $1.0$.
- Now note that for replication 2, the initial ```v_beta_reduct``` is \textit{not} $0.9$ as it should be -- because proper clearing or resetting has not occurred! The initial ```v_beta_reduct``` is $0.7$ and the ```prev``` value is $.01$
  - The ```prev``` are properly reset and start from the same value and increase in the same way within different replications because ```prev``` is passed outside of the vaccine-related objects.
  - Note that ```v_beta_reduct``` \textit{does not change} within replication 2! See the ```delta_update``` code pasted above. Turns out, the value of ```self.v_beta_reduct_delta``` for this group is $0.7$, so once ```v_beta_reduct``` is also ```0.7```, the value of ```v_beta_reduct``` does not change despite updates. 
- This is all why conditional on a seed not being simulated first, the seed's $R^2$ is the same, regardless of order.
- The $R^2$ for Seed 100 for replications 1, 2, and 3 respectively are: rsq -1.1432008293623226, rsq -1.174342314895255, and rsq -1.174342314895255. The first and second values are different but the second and third values are the same.

## The Fix

- To further confirm my hypothesis, I ran tests in which subsequent replications use fresh, unadulterated deep copies of the ```vaccine_policy``` object, rather than using the same instance but calling the ```reset_history()``` method in between replications. Using fresh copies fixed the problem. Now seeds give the correct $R^2$ and their $R^2$ does not change depending on whether or not they are simulated first. 
- In the code, my current plan is to update the ```reset_history()``` method to properly reset the ```v_beta_reduct``` and ```v_tau_reduct``` variables. I will check for any other variables that are not getting reset in between replications as well.
- I will check any changes versus the \textit{original code} with the \text{fresh copies} (so, a debugged version of the original code).
- A further modification, as part of a general restructuring plan, is to more clearly delineate which variables or attributes \textit{stay the same, regardless of replication}, and which ones \textit{change within a replication and therefore need to be reset}. This delineation has an additional advantage. Rather than copying or recreating an entire instance (and all of its many attributes), we may only need to copy some of its attributes between replications. 

## Possible Consequences

- Any analysis using the original code is possibly suspect.
- In particular, I do not think we should use any previous seeds to "warm start" sample path generation in the new code.

# 07272022 Meeting

## Code Edits
- I am only going to edit the constant "regular" multi-tier policy and deal with the ACS stuff later

- ```policy_multi_iterator``` in ```threshold_policy.py```
  - No reason for ```instance``` (instance of ```Instance``` in ```__init__.py```) to be passed or returned -- it gets used in every single instantiation of ```MultiTierPolicy``` but it is already "global" in the sense that all processors have access to it
  - No reason for ```obj_fun``` to be passed or returned either
  - No reason for ```interventions``` to be returned -- and if we can fix ```run_multi_calendar```, no reason for it to be passed either
  - No reason for ```fixed_vaccine_policy``` to be passed and returned either -- it does not get edited in this function
  - Lines about ```first_day_month_index``` seem to be unnecessary (they seem to be an artifact of old code) -- they are not used anywhere in this function, so we delete them

# 07212022 Contact Matrix Questions

- I am not confident that the current version of the code generates contact matrices correctly. The code below is a suspicious snippet. This code below is from ```simulate_t``` from the file ```SEIYARDH.py```, which is called as a subroutine for every day $t = 1, 2, \dots$. See \texttt{trigger\_policy\_search.pdf} for a mindmap of the main function ```trigger_policy_search``` which is used for optimization. 

```{}
        for t_idx in range(1):
            t = t_date
            k_t =  policy._intervention_history[t]
            phi_t = interventions[k_t].phi(calendar.get_day_type(t))

            print(t, interventions[k_t].SC, interventions[k_t].SD, interventions[k_t].CO, policy._tier_history[t])
```

- Below, ```phi_t``` is the contact matrices at day $t$. The shape of ```phi_t``` is $(5,2,5,2)$. So, ```phi_t``` has $5$ elements, and each element is an array with $2$ matrices, and each matrix is $5 \times 2$. 

- Question: not sure why ```phi_t``` has these dimensions -- these do not appear to be the "baseline contact matrices" -- is this just for the age group of $65$ years and older and for the high risk group? Even so, still confused about the dimensions.

- Here, ```interventions``` is a list of instances of ```Intervensions.``` Each instance of ```Intervensions``` includes attributes ```SC```, ```SD```, ```CO``` corresponding to whether or not schools are closed, the social distancing number, and the cocooning number, respectively. 

- I added the print statement to print the day, SC, SD, and CO of the ```Intervensions``` instance being used to generate ```phi_t.``` And I also printed the tier number ($0, 1, 2, 3, 4$). 

- Note that a theme of my reform for the code is that the seed generation should be separate from the optimization, so even though the current version of the code does compute the tier before the vertical line, I do not think we should! (This is a redundant and unnecessary computation for every single replication.)

- What I believe should happen if the code is correct:
  - The SC, SD, and CO tuple should match the historical data before "the vertical line" (before the optimization starts) --> THIS SEEMS FALSE!
  - The tuple should correspond to the SC, SD, and CO parameters from the tiers after the vertical line (after the optimization). For example, if at day $900$, we are in tier $5$, and tier $5$ means schools closed, social distancing is $0.99$, and CO is $0.99$, then the tuple should reflect that --> THIS SEEMS OK! (I did not systematically check this, but printed out some sample paths and checked manually.)

- See \texttt{transmission\_new.csv} and \texttt{07212022outputA.txt} and compare. If I were more sophisticated I would have generated a script to automatically check differences, but I just inspected by hand here. I will write a script later if necessary. Alot of the SD, CO pairs do agree with the historical data, but there are important discrepancies.

- For example (not an exhaustive list):
  - Line number 246 (line numbers are directly comparable, ignore the day counter in the .txt file):
    - Historical data for SD, CO: 0.778334,0.827015
    - What the simulation uses for SD, CO: 0.75298 0.787752 (and this discrepancy persists for dozens of days)
  - Line number 278
    - Historical SD, CO: 0.75298,0.787752
    - Ours: 0.674321 0.827015
  - Is it the case that our SD, CO is correct-ish but \textit{ahead} of the historical data? Maybe? Here's another case that might support that hypothesis:
  - Line number 121:
    - Historical SD, CO: 0.641986,0.787752
    - Ours: 0.827015 0.827015
  - Line number 134 (we agree with the historical data):
    - Historical SD, CO: 0.827015,0.827015
    - Ours: 0.827015 0.827015
  - Note there is also data disagreement on line number 830 (the last historical data point)

- Some good news is that school closures do seem to be correctly incorporated (at least based on looking at a few sample paths and checking manually). In the setup data json file, historical school closure dates are specified, and these agree with the SC toggles that I printed!  

\newpage

# 07202022 Meeting

## Some items for meeting
- Cost (objective function) is computed over entire time horizon (including historical data dates), not over optimization period only
- Contact matrices are not correct
- Optimization occurs during historical period (artifact of old version of code)
- Community transmission subroutine overrides the specified policy tiers
- Schools closed?

\newpage

# Some code notes for myself

## Figuring out simulation stuff
- Arguments in ```trigger_policy_search``` 
  - ```instance``` is an instance of ```Instance``` class lol in ```__init__.py```
  - note the ```tiers``` argument refers to the list of stages and key values such as the cocooning impact, whether or not schools are closed, and daily cost, as well as candidate thresholds (this is in a json file) -- this also does not need to be passed
  - ```vaccines``` is an instance of ```Vaccine``` in ```vaccine_params.py``` -- need to figure out if this gets changed -- it's possible that this does not need to be passed either
  - ```obj_func``` refers to ```multi_tier_objective``` function from ```objective_functions.py``` -- this keeps getting passed but there is no reason for this to get passed -- ```multi_tier_objective``` takes ```instance``` which is an instance of ```Instance``` class lol in ```__init__.py```, ```policy``` which is an instance of ```MultiTierPolicy``` in ```trigger_policies.py```, ```sim_output``` -- but here is an opportunity for efficiency gains, because we only extract ```ICU``` from ```sim_output``` so we do not need all of ```sim_output```, and finally ```*kwargs``` for different flags to indicate what to compute
  - ```policy``` (```selected_policy```) is ```None``` when there is not a policy specified and it means we search for a policy
  - ```selected_vaccine_policy``` is an instance of ```VaccineAllocationPolicy``` in ```vaccine_policies.py```
  - I don't think we have to pass ```mp_pool``` either
  - Other arguments are self-explanatory or keyword type arguments specifying different parameters for the simulation and optimization and whatnot
  
Other stuff
- ```interventions_train```  ```form_interventions``` in ```interventions.py``` -- it is a list of instances of ```Intervension``` objects in ```interventions.py``` -- each ```Intervension``` instance is built with school closure levels, cocoon levels, and social distancing levels

\newpage

# 07182022 Email Update

## Overview
- There were 2 hypotheses for the slow running code:
  - 1: not using the correct files and historical end dates -- this has been debunked -- we are indeed using the correct .csv input files
  - 2: when optimizing over multiple policies, the seed search  (generating sample paths and selecting those with high $R^2$) occurs for each policy -- this has also been debunked, as I will show here
- One suggestion was to only input one policy and see how long seed generation takes -- since this is quite time consuming, I did not do this and instead checked the hypothesis directly by adding print statements to the code and checking the code output on smaller cases

## Hypothesis 2 incorrect
- See 07142022outputA.txt 
- We input 2 policies to test, with a training set size of $2$
- Every time a simulation is run (for any policy), we print the $R^2$ value of the sample path that the simulation is run on 
- For the 1st policy, there are about 2 dozen $R^2$ print statements corresponding to the number of sample paths needed to generate $2$ good realistic seeds
- For the 2nd policy, there are only $2$ $R^2$ print statements, and both $R^2$ values are above $0.75$ -- this indicates that after the 1st policy, seed generation stops 
- This is also corroborated by looking at the loop structure and if-then structure in the code in the function ```trigger_policy_search``` in ```policy_search_functions.py```

## Previous cluster experiment realization
- Recall: my previous cluster experiment took about $36$ hours to run $1650 \times 6$ replications (ignoring the roughly $160$ replications from sample path generation) over $80$ processors. I ran this \textit{twice} to double check and got about the same timing.
- I realized that since I requested $4$ training reps and $2$ testing reps, we are only using max $4$ processors and $2$ processors for the training and testing seed generation, respectively. Therefore the timing is not as bad as we thought...
- So the above statement is for roughly $4$ processors rather than $80$ processors.

## Back-of-the-envelope calculations
- HOWEVER, there are diminishing returns from more and more parallel processors.
- We print the time it takes to simulate $2$ replications (regardless of $R^2$)
- It takes about $25$ seconds to simulate a replication (from the start to the optimization end date) with $1$ processor (on my computer).
- It takes about $47$ seconds to simulate $8$ replications with $8$ processors (on my computer). So it takes $6$ seconds to get $1$ replication, roughly.
- And $68$ seconds to simulate $12$ replications with $12$ processors (on my computer). So it takes $5.7$ seconds to get $1$ replication, roughly. 
- And $78$ seconds to simulate $80$ reps with $80$ processors (on the cluster, on a single reserved node). So it takes about $1$ second per replication.
- Simulation times may vary depending on the policy, and I only tested a few replications, but I think this experiment is illustrative.
- Doing a very rough calculation... assuming it takes about $1$ second to generate a seed with $80$ processors, $0.07\%$ of seeds generated have good $R^2$ (taken from old paper response), then it would take $(600/0.0007)/(3600*24)$ days (roughly $10$ days) to generate $300+300$ seeds.
- If we have $1650$ policies, evaluating them on the training set would take about $5-6$ days. 
- So, we still need to make adjustments and speed up the seed generaiton and simulation process.

```{}

start = time.time()

out_sample_configs = stoch_simulation_iterator(instance, vaccines, policy_i, selected_vaccine_policy, obj_func, interventions_train, det_sample_path = False, crn_seeds=crn_input, seed_shift=seed_shift_var, n_replicas=chunkinput, **kwargs_out) 
                    
out_sample_outputs = simulate_p(mp_pool, out_sample_configs)          

print(time.time() - start)
```

## Other hypotheses for the slowness of the simulation/optimization
- Passing and returning unnecessary object instances -- this is bad for parallel processing in the ```multiprocessing``` module because to communicate the objects between processors, we must ```pickle``` the objects
- (Related to the above comment) for each policy, we divide the simulation replications needed for that policy amongst $p$ processors. It would be more efficient to divide \textit{policies} amongst $p$ processors. The reason is that "loading" a policy has a fixed cost (including pickling costs). If we divide a policy's replications amongst $p$ processors, then for each policy, we are incurring an extra $O(p)$ fixed cost charges because each processor must "load" the same policy. 
- There is a lot of unnecessary copying -- I need to spend more time with the code to understand why this is done -- but this is certainly slow! 
  - As an important note, there are hardcoded functions called ```deep_copy``` (well, methods for some objects) -- this is actually really dangerous because these functions do not do what they say they do. They do \textit{not} deep copy. They shallow copy!!!! Particularly when shallow copying mutable objects such as lists, multiple processors can accidentally affect the same object, which can lead to unintended negative consequences. 
- This all also shows the importance of checking timeblocks and terminating a sample path early -- unfortunately, I do not see any version of the code that simulates a sample path in timeblocks (Haoxiang's version on github does not do this either -- see ```policy_search_functions.py``` in his repository). Even worse, when generating a seed or sample path, the sample path is created for the \textit{entire timeframe up to the end date, rather than to the end of the historical data}. Since only data up to the end of the historical data is used in the $R^2$ calculations, this is very inefficient. 
  - Right now it is not obvious to me how to simulate a sample path in chunks -- specifically, how to start, stop, and then continue a simulation (how to stop at the end of a timeblock, check the $R^2$, and then potentially continue the simulation from that point if the sample path has so far survived the $R^2$ check). I am not even sure it is possible with the current structure of the code. This will take some time to figure out or code. 
  
## Notes
- Ideally, we would save the simulation state rather than the random number seed -- if there is a seed that generates a realistic sample path, this is difficult because if we change the simulation model ever so slightly, the random number seed does not necessarily work 

\newpage

# 07072022 Meeting

# Questions
- How long did the optimization take in the most recent publication, and what were the experiment configuration parameters like ```grid_size```, ```pub``` etc? How many candidate policies were tested? 

# CRN
- Used inversion and one uniform random variable per each binomial random variable generation (specifically used ```scipy.stats.binom.ppf```)
- Verdict: in some instances, roughly a factor of $10$ variance reduction! but a factor of $10$ execution time inflation with the naive ```scipy``` binom implementation
- We could potentially use ```C``` and ```Cython``` to write a speedy routine and call it instead of calling the ```scipy``` implementation
- Setup
  - S/E/I/R, beta/sigma/gamma/xi, days
  - All have same S/E/I/R of 1mil - 1k, 0, 1k, 0
  - All for 1k days
  - Disease A: .2, .5, .1, .05
  - Disease B: .3, .6, .1, .05
  - Disease C: .9, .1, .1, .5
  - Disease D: .6, .5, .1, .05
- A versus D: 8e4 versus 33e4 -- about 75% reduction
- B versus D: 32s versus 2s execution time -- and 3e4 versus 35e4 -- about 91% reduction
- C versus D: 1e5 versus 3e5 -- about 65% reduction

# Optimization on the cluster
- See ```0707clusteroptimization.txt```
- One issue: the time it takes to run the optimization
  - 1650 policies, 4 training reps, 2 testing reps, 80 processors
  - Took 36 hours
  - For 300 training reps and 300 testing reps, would take 112.5 DAYS
- Also, there were only two cost values: 1171571 or 1172224 -- is this an error?
- Square root staffing rule pruned 0 policies! Should we axe this part?

# And getting more information on output distribution
- The daily costs are:
  - Stage 2 / blue: 1
  - Stage 3 / yellow: 10
  - Stage 4 / orange: 100
  - Stage 5 / red: 10000
- DM says also get number of days that patient capacity was violated
- for ICU capacity, can do
```
np.sum(sim_j[config["infeasible_field"]] > infeasible_cap_field[config['infeasible_field']])
```
- I noticed that counting the number of days of ICU capacity violations historically and over the whole timeframe resulted in the same answer for every replication -- is this correct? 
- Policy tested: Stage1_-1_-1_Stage2_1_1_Stage3_30_30_Stage4_90_90_Stage5_500_500 (optimal policy from the Yang et al. paper)
- See 07072022 .png files on 40 replications 

# Note on timeblocks
- Double-checked and unfortunately Yang et al. Algorithm 1 is not implemented in the most recent code (or Haoxiang's code)
- It looks like there was an attempt to implement this, but only for the testing set, and this is commented out (have not tested if it works or not)
- The issue is that the way the code is written... there is no simulation-by-timeblocks. We run a simulation replication across the entire timeframe (not just until the end of the historical data). In the attempted timeblocks implementation, this is also the case. So, I'm not sure there are significant gains in checking $R^2$ by timeblocks if we are not simulating by timeblocks.
- I think that being able to simulate in increments would be great, but I think this would take a major restructuring of the code.

# Optimizing the optimization
- Probably easier to explain on a whiteboard
- Using ```multiprocessing``` in this way is not efficient
- Plus passing objects unnecessarily is especially inefficient in parallel due to pickling
- There are major question marks with copies and deep copies -- I think a lot of these are unnecessary
- PSS/bi-PASS on top! And ideally have modular code of: sample path generation, deterministic queries, simulation, and optimization. And a single file that combines all of these when running the overall optimization.

# More optimization notes
- even if a specific threshold is not specified, if there is only one option in the candidate thresholds (tiers json file), then the testing set is skipped -- THIS SHOULD BE DOCUMENTED
- ```all_outputs = simulate_p``` (see ```policy_search_functions.py```)
  - each element has tuple: ```outsim```, ```policy_cost```, ```policy```, ```thrs```, ```seed```, ```kwargs```
  - ```outsim``` returns dictionary of epidemiological variables such as number in hospital -- this is what's really needed
  - ```policy``` is an instance of ```MultiTierPolicy``` class (from ```trigger_policies.py```)
  - ```thrs``` is an instance of ```VaccineAllocationPolicy``` class (from ```vaccine_policies.py```)
- passing ```policy``` and ```thrs``` is unnecessarily and potentially quite costly!
- in ```policy_search_functions.py``` these instances are called ```policy_i``` and ```_vac_policy``` respectively
- ```policy_i``` is only used for printing the string of the name! There is no reason to pass the object!
- ```_vac_policy``` is actually never used!
- Also note that ```policy.deep_copy``` DOES NOT ACTUALLY DEEP COPY! IT CREATES A SHALLOW COPY! I'm not sure this is actually an issue but it's important to note

# Questions for self
- What happens if specified candidate thresholds have overlap for tiers? e.g. tier 2 candidates: [10, 20] and tier 3 candidates: [10, 20] -- so that tier 2 could be 20 and tier 3 could be 10 -- which obviously would not make sense -- but is this allowed? 
  - I think this actually is handled correctly -- see ```trigger_policies.py``` lines ```37--46```
- Is there any use for ```trigger_policy_search_det``` in ```policy_search_functions.py```? I thought that the deterministic simulation run was just a special case of the regular simulation run -- with random seed equal to $-1$ to specify that the expected values of binomials are used rather than random sampling of binomials.

# simulate_p output

\newpage

# 06222022 Meeting

# TO DO / Questions for self
- Less thorough online notes than last week -- transfer handwritten notes to here 
- What happens to multiprocessing pool shenanigans when more processors than replications? Hopefully it's not a problem? But I'm concerned about the random number allocation... like, do multiple processors get the same (redundant) seed?

# Questions for meeting
- Square root staffing deterministically -- what happens to the triangular distributions, are those detemrinistic too?
- How to check $R^2$ "on the fly" and terminate early?

# Some agenda items
- CRN rabbit hole resolution
- Generating realistic sample paths 
- Optimization improvements

# PASS notes
- Current simulation state
```
first screen deterministically using square root staffing rool
for each policy:
  while training set reps not simulated:
    simulate p reps
pick best feasible solution
```

# Notes on trying to run the optimization on the cluster
- Worked with Johnathan to get python3 and pip3 all setup -- see email chain for details
- I'm getting the same costs when there are 2 training set replications and I'm testing the last tier values of 50, ... 80 -- I'm guessing it's because these policies are too close together? I'm hoping it's not a bug. 
- see ```build_multi_tier_policy_candidates``` in ```trigger_policies.py```
- Line 35: ```candidates = [gz * i for i in range(0, int(lambda_start / gz) + 1)] + [lambda_start]```
- ```lambda_start``` is policy upper bound (```pub```) argument -- the reasoning for the variable name change is unclear smh
- this is a WARNING: I think bad stuff happens if ```grid_size``` makes the above list comprehension take weird values -- setting ```grid_size = 1``` in the .json file seems to be the way to go
- RuntimeWarning makes the program stop on the cluster! running with ```python 3.7 -W ignore``` makes it work though
```
/home/lpei/scratch/06202022/COVID19-vaccine-main/VaccineAllocation/SEIYAHRD.py:210: RuntimeWarning: invalid value encountered in true_divide
  ICU_ratio = np.sum(ICU, axis=(1, 2))[:T]/(np.sum(ICU, axis=(1, 2))[:T] + np.sum(IH, axis=(1, 2))[:T]
```

# 06152022 MEETING

# Generating realistic seeds
- Idea for seeds: sample a butt ton (this is scientifically correct phrasing)
- Use these samples to fit a distribution for REALISTIC combos of the parameters
- Fit the JOINT distribution, don't only look at the marginals
- Then sample from this "intelligent" distribution and start the simulation from the last historical data point!!!!!!

# RNG current state and proposed reform
- It seems like we do use CRN for binomial random variables? When we generate realistic seeds (realistic sample paths), we pass the seed to every random variable generation call -- including the binomial random variables
- Using the new realistic seeds generation -- don't save the SEED, save the epidemiological parameter actualizations, and then use a seed (separate bit generator) for binomial random variables
- Idea is to make realistic seed generation separate from the optimization -- currently, these two are conflated, leading to inefficiencies
- Major inefficiencies with current generation of realistic seeds :
  - For each policy, we simulate over all timepoints, and then after checking $R^2$, we throw out replications with unrealistic seeds
  - We check $R^2$ for every seed for every policy, even after we have formed a training set and even if we read in a seeds file -- see bottom of ```samplepathseedsbug2.txt``` for an example
- There are also inefficiencies with passing/returning unecessary objects, and also returning output for every single day for each performance measure -- for the optimization, we only need 1 aggregate datapoint for feasibility and the objective function respectively!
- Below is a summary of the code from lines 95-194 in ```policy_search_functions.py```
```{}

# pseudocode summary of outer loops -- details deleted
for each threshold candidate:
  get (deterministic) simulation replications and check sqrt staffing rule
  if feasible:
    while number of realistic seeds < training set size:
        get (stochastic) simulation replications
            
            # real code here
            for sample_ij in out_sample_outputs:
                sim_j, cost_j, policy_j, _vac_policy, seed_j, kwargs_j = sample_ij
                real_hosp_end_ix = len(hosp_benchmark) 
                IH_sim = sim_j['IHT'][0:real_hosp_end_ix]
                IH_sim = IH_sim.sum(axis=(2,1))
                f_benchmark = hosp_benchmark
            
                rsq = 1 - np.sum(((np.array(IH_sim) - np.array(f_benchmark))**2))/sum((np.array(f_benchmark) - np.mean(np.array(f_benchmark)))**2)
    
                if rsq > 0.75:
                    stoch_outputs_i.append(sample_ij)
                    crn_seeds_i.append(seed_j)
                    if len(stoch_outputs_i) == n_replicas_train:
                        break
```
- Another benefit to separating ```calibration''' (generating realistic seeds) and simulation/optimization stages is that we do not need to pass candidate thresholds as arguments when simulating to get realistic seeds -- because whether or not a seed is realistic does not depend on the policy
- Also see the following links for why we should use ```Generator``` instead of the currently implemented (but legacy) ```RandomState```
  - https://numpy.org/doc/stable/reference/random/legacy.html
  - https://numpy.org/neps/nep-0019-rng-policy.html
  - https://builtin.com/data-science/numpy-random-seed
  - https://albertcthomas.github.io/good-practices-random-number-generators/
- From the first link:
  - This usage is discouraged, as it is implemented via a global RandomState instance which is not advised on two counts: It uses global state, which means results will change as the code changes[.] It uses a RandomState rather than the more modern Generator.For backward compatible legacy reasons, we cannot change this.

# Generating binomial random variables
- Numpy source code urls (in particular see random_binomial in second link):
  - https://github.com/numpy/numpy/blob/main/numpy/random/_generator.pyx
  - https://github.com/numpy/numpy/blob/main/numpy/random/src/distributions/distributions.c
- Python implementation
  - if $p \le 0.5$ and $pn \le 30$ or $(1-p)n \le 30$, use inversion
  - otherwise use BTPE -- which is an accept-reject method that only works when $n \min(p, 1-p) \ge 10$, which dominates other constant memory algorithms (see paper for details)
- I would think that CRN would not do much with accept-reject? Since different numbers of uniform random variables are used? And yet...

# Variance reduction using CRN for binomial random variables
- Made a baby SEIRS model (without vital dynamics, i.e., no births or deaths) -- the 2nd S refers to us allowing recovered individuals to return to a susceptible state
- Very rough grid -- only iterates once a day
- The overall population N changes due to discretization error -- when I take away randomness though, N is always the same (gut check for correctness of code)
- Based on https://docs.idmod.org/projects/emod-hiv/en/latest/model-seir.html
- Code is in ```SEIR_toy.py```
```{}
# all have S0 = 1e6, end_time = 1e3, num_reps = 1e2
# diseaseA: beta = 0.2 and sigma = 0.5 (50% of infection after exposure)
# diseaseB: similar to diseaseA, but slightly higher beta and sigma
# diseaseC: beta = 0.9 (very high exposure rate), sigma = 0.1 (lower infection rate), 
#           xi = 0.5 (high reinfection rate)

diseaseA_seed1 = SEIR(int(1e6)-int(1e3), 0, int(1e3), 0, .2, .5, .1, .05, int(1e3), 1)
diseaseA_seed1_data = diseaseA_seed1.run_multiple_reps(int(1e2))

diseaseB_seed1 = SEIR(int(1e6)-int(1e3), 0, int(1e3), 0, .3, .6, .1, .05, int(1e3), 1)
diseaseB_seed1_data = diseaseB_seed1.run_multiple_reps(int(1e2))

diseaseB_seed2 = SEIR(int(1e6)-int(1e3), 0, int(1e3), 0, .3, .6, .1, .05, int(1e3), 2)
diseaseB_seed2_data = diseaseB_seed2.run_multiple_reps(int(1e2))

diseaseC_seed1 = SEIR(int(1e6)-int(1e3), 0, int(1e3), 0, .9, .1, .1, .5, int(1e3), 1)
diseaseC_seed1_data = diseaseC_seed1.run_multiple_reps(int(1e2))

diseaseC_seed2 = SEIR(int(1e6)-int(1e3), 0, int(1e3), 0, .9, .1, .1, .5, int(1e3), 2)
diseaseC_seed2_data = diseaseC_seed2.run_multiple_reps(int(1e2))

A_B_regular = compute_sample_variance_of_difference(diseaseA_seed1_data, diseaseB_seed2_data)
A_B_CRN = compute_sample_variance_of_difference(diseaseA_seed1_data, diseaseB_seed1_data)

A_C_regular = compute_sample_variance_of_difference(diseaseA_seed1_data, diseaseC_seed2_data)
A_C_CRN = compute_sample_variance_of_difference(diseaseA_seed1_data, diseaseC_seed1_data)
```
- I'm comparing A versus B (two similar diseases)
  - Sample variance of difference without CRN and with CRN: about $18.1$mil versus $16.2$mil (roughly $10\%$ reduction)
- And also B versus C (two different diseases)
  - Sample variance of difference without CRN and with CRN: about $57.8$mil versus $38.1$ (roughly $29\%$ reduction)
  
# bi-PASS
- Important note: CRN actually makes bi-PASS worse (when systems have different variances, which presumably is the case here) -- but for the known standard PSS case, which is our case for feasibility checking, CRN does not have a negative effect
- Does CRN even help though, if we are not doing pairwise comparisons for feasibility checking?
- After resolving the generating realistic seeds issue and separating calibration from simulation/optimization, can implement PSS for chance constraint feasibility checking "embedded" within the policy search function
- Then the question is whether to implement bi-PASS for optimality, and if so, how to implement it (as a wrapper on top)?
- Stochastic dominance -- maybe set alpha level very small ($1-\alpha = 0.99$) -- and if a policy is infeasible, also eliminate all ```looser''' policies?
  - The issue is there seems to be a domino effect of false eliminations
  - If there are $100$ policies stricter than policy $A$, which is actually chance constraint feasible, then if any of the $100$ policies are falsely eliminated, $A$ gets eliminated too.
- Verify/compare results to different optimization problems run on the original version of the code
- LP note/idea for later: related to BLN's PASS as systems-revealed-sequentially screening -- generate solutions on the fly based on sqrt staffing rule and hospital constraint feasibility? Woof!

# Also briefly mention code documentation...

\newpage

# CODE NOTES

# Explanation of Code Notes

- LP's notes on the code (potentially sassy and unfiltered, apologies)
- Based on my personal understanding......
- First pass -- on second pass will add more detail
- Overview of functions but skipped function and class arguments for now

# Typos
- triger 
- intervension
- transmision (I think)

# High Level

Add this to top of main_allocation.py
IMHO this is a better fix than futzing with $PYTHONPATH

```{}
import sys
sys.path.append("//Users/lindapei/Dropbox/RESEARCH/Summer2022/COVID19-vaccine-main/VaccineAllocation")
sys.path.append("/Users/lindapei/Dropbox/RESEARCH/Summer2022/COVID19-vaccine-main")
```

## Categorization of Files

## Acronyms

- SC: school closure
- CO: cocooning
- SD: social distancing

# Issues

## debugging trigger_policy_search
- concerned about seed generation...
- I think we are unnecessarily generating seeds for each policy, and this is very time consuming
- sample paths should not depend on the policy

## cannot run optimization 
- supposedly removing ```-gt [-1, 5, 15, 30, 50]``` and not specifying a specific threshold runs the optimization
- this is not the case -- this doesn't work -- the code then only runs [-1, 5, 15, 30, 50], which is hardcoded as threshold candidate(s) in tiers5_opt_Final.json
- austin_test_IHT.json has ```grid_size``` -- unclear what this does lol
- I thought the optimization was supposed to automatically generate candidates according to the grid size and predetermined upper and lower bounds -- but the only way I can get the optimization to work is by explicitly coding the threshold candidates for each level that I want to test
- Guyi said that if the last date in ```transmission.csv``` is before the end of the simulation time (given in some setup file), then the optimization should trigger without a prespecified threshold -- but this is not true
- fix: explicitly specify candidate thresholds to test in tiers json file, e.g. ```[50, 55]``` (list)
- fix: set candidate thresholds to null in tiers json file, and adjust grid_size in config >> austin json file and also ```-pub``` (policy upper bound) argument as script argument

# main_allocation in depth
- ```parse_arguments()``` in ```utils.py``` -- takes the command line arguments -- reads files and also has computing toggles (matplotlib stuff)
- question: what is the seeds.p file? Nazlican's github says it will be generated in /output -- I'm guessing I need to first run this to get the seeds?
- Kevin's tutorial and my best guess poking around the files: -seed=new_seed.p (it's in the ```instances/austin``` folder)
- Ok, cool -- I still get the runtime warning -- but I get a sensible rsq -- there are differences (cost differences) compared to kevin's results, but this is better -- i noticed that the filenames are different so it's possible that there's different data too
- The tiers ```tiers5_opt_Final.json```-- specify transmission reduction and costs at each stage -- but then the optimization chooses the actual levels for each stage
- instance creates instance of ```Instance``` class (defined in ```__init__.py```) -- loads historical data and epidemiological parameters
- ```selected_policy``` is an instance of ```MultiTierPolicy```  (abbreviated MTP) class from ```TriggerPolicies.py```-- 
- so for a constant policy, a given date is not needed -- I guess it's only to determine the step functions and linear functions type policies -- I don't think I will need this
- ```selected_vaccine_policy``` is an instance of ```VaccineAllocationPolicy``` (abbreviated VAP) class from ```vaccine_policies``` 
- then either ```trigger_policy_search_det``` or ```trigger_policy_search``` from ```policy_search_functions.py```
  - ```trigger_policy_search```: "search for optimal trigger policy with a fixed vaccine policy" -- this is very vague and confusing so let's figure this out... -- 
  - what does "build interventions according to input tiers" mean? this goes back to my confusion about what an intervention is specifically
  - ```build_multi_tier_policy_candidates``` from ```trigger_policies.py``` -- builds candidate policies? 
  - I think the candidate thresholds (defined in tiers .json file) are used to guide the grid search? But I need to double check
  - within ```threshold_policies.py```, ```run_multi_calendar``` is used in ```policy_multi_iterator```, which creates an iterator of the candidate thresholds for each tier
  - ```policy_multi_iterator``` calls ```build_multi_tier_policy_candidates```
  - within ```trigger_policy_search```...
    - ```simulate_p``` which lives in ```SEIYARDH.py``` -- and this maps ```system_simulation``` -- which runs ```simulate_vaccine``` which calls ```simulate_t``` as a subroutine
    - then find the best feasible candidate! but skip this if there is only one candidate
- So I guess if seeds are not specified... we do accept reject within ```trigger_policy_search``` to generate seeds with rsq > 0.75? It's not exactly rsq so apparently it does not have to be within [0,1].

# File Overviews

## main_allocation
- imports ```utils```
- imports ```load_config_file``` and ```change_paths``` from ```VaccineAllocation''' (folder) but I don't know where those are????
- imports ```instances''' (folder)
- imports ```objective_functions```, ```trigger_policies```, ```vaccine_policies```, ```policy_search_functions```
- essentially calls ```trigger_policy_search``` (or the deterministic version depending on the arguments)

## main_least_squares
- imports ```load_config_file``` and ```instances_path``` from ```VaccineAllocation```
- imports ```instances```, ```objective_functions```, ```vaccine_policies```, ```least_squares_fit```
- no functions
- creates ```transmision``` csv file
- from nazlican's github: fit transmission-reduction parameters and certain dynamics in use of the ICU and hospital duration

## objective_functions
- as the name says :)
- does not import any other COVID19 files
- ```multi_tier_objective``` and ```multi_tier_objective_ACS``` functions

## pipelinemultitier
- imports ```reporting``` (folder)
- from nazlican's github: generating plots after creating output files
- functions ```read_hosp```, ```icu_pipeline```, ```report```

## interventions
- imports ```SEIYAHRD``` only
- ```Intervension``` class -- has attributes for school closure y/n, cocooning level, social distancing level, some epidemiological parameters
- There is an unnecessary use of ```@property``` here unfortunately -- this slows down the code
- ```create_intLevel``` -- get intervention levels from school closure, cocooning, social distancing? 
- ```form_interventions''' -- make list of ```Intervension``` objects -- also not totally sure what this does

## main_ACS
- Going to skip along with ```ACS_script``` for now

## ACS_script
- Going to skip along with ```main_ACS``` for now

## least_squares_fit
- imports ```pipelinemultitier```, ```interventions```, ```SEIYAHRD```, ```config``` (folder) from ```VaccineAllocation``` (folder), ```threshold_policy```, ```objective_functions```, ```trigger_policies```, ```vaccine_policies```
- "utility" functions for computing least squares: ```deterministic_path```, ```residual_error```, ```least_squares_fit```, ```run_fit```

## epi_params
- does not import any other COVID19 modules
- ```EpiSetup``` class for SEIR simulation parameters and base contact matrices 
- ```ParamDistribution``` class for parameters of the random distributions

## policy_search_functions
- imports ```interventions```, ```SEIYAHRD```, ```utils```, ```threshold_policy```
- also imports from VaccineAllocation: ```config```, ```logger```, ```output_path```
- ```trigger_policy_search``` -- search for optimal trigger policy given fixed vaccine policy
- ```trigger_policy_search_det``` -- above function but deterministically
- ```capacity_policy_search``` -- not sure what the difference between this and the first function is? is this the overall optimization?

## SEIYAHRD
- Refers to S, E, IA, IY, IH, R, D epidemiological variables
- I'm just going to call this the SEIR simulation
- Imports ```utils```, ```vaccine_policies```, ```trigger_policies```, ```config```
- ```immune_escape``` -- moves recovered and vaccinated individuals to waning efficacy susceptible compartment
- ```simulate_vaccine``` -- loops over days $t$ to simulate SEIR simulation -- if seed is ```-1``` then run deterministically
- ```simulate_t``` -- subroutine for ```simulate_vaccine``` -- simulates for each $t$
- ```rv_gen``` -- either returns expected value if deterministic simulation or returns binomial random variable for SEIR simulation transitions
- ```system_simulation``` -- gets mapped when running parallel simulations -- calls ```simulate_vaccine```
- ```simulate_p``` -- runs simulation in parallel -- maps ```system_simulation'''
- ```dummy_cost``` -- returns $0$ lol
- ```fix_policy``` -- just returns ```z[t]``` 
- ```get_next_month``` -- function for date and time shenanigans
- ```discrete_approx``` -- separate each day into timesteps
- ```SimCalendar``` class -- a calendar to map time steps to days and determine if the day is a weekday/weekend/holiday/etc
  - Has various methods for date fetching I will not detail here
  - Importantly, has methods such as ```load_predefined_lockdown``` -- which I presume are also important for incorporating previous data and previous gov interventions (calibration and sample path step)? Double check this 
  
## threshold_policy
- Module for computing threshold policies
- Imports ```trigger_policies```, ```config```
- ```run_multi_calendar``` -- called as subroutine in the other 3 functions -- creates ```z_ini``` (not sure yet but some sort of initial state), ```SD_state``` which is I'm guessing related to ```sd_levels``` which maps lockdown status to transmission reduction, and ```feasible_interventions```
- ```policy_multi_iterator``` -- creates iterator of candidate thresholds for each tier -- goes into ```simulate_p``` for parallel use in module ```SEIYAHRD```
- ```stochastic_iterator``` -- creates iterator for different replications and changes the seed -- also used in ```simulate_p```
- ```stoch_simulation_iterator``` -- same as above but for the SEIR simulation? 

## trigger_policies
- different trigger policies to simulate
- this file creates the candidate mesh of feasible policies to simulate (because we cannot handle ``true'' optimization, we have to grid search/test)
- 3 functions: ```build_multi_tier_policy_candidates```, ```build_ACS_policy_candidates```, ```build_CDC_policy_thresholds```
- 3 corresponding classes: ```CDCTierPolicy```, ```MultiTierPolicy```, ```MultiTierPolicy_ACS```

## vaccine_params
- imports ```config```
- ```Vaccine``` class and ```Vaccine_group``` class
  
## vaccine_policies
- different vaccine allocation policies to simulate
- imports ```trigger_policies``` (only uses ```MultiTierPolicy```)
- ```VaccineAllocationPolicy``` class
- ```fix_hist_allocation``` -- fix historical attributes
- ```find_rollout_allocation``` -- assign vaccine to active group until end time or all vaccinated

## utils
- does not import any of the other COVID19 modules
- not super relevant IMHO
- has some mathematical functions, a timing method, and stuff for parsing

## __init__
- like utils, does not import any other COVID19 modules, not super relevant
- just for setting project paths